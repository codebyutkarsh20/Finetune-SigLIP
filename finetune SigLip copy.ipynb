{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23173,"status":"ok","timestamp":1723128930290,"user":{"displayName":"utkarsh patidar","userId":"01573665842487995951"},"user_tz":-330},"id":"uVW7BXhYj-zu","outputId":"a18e1b96-b858-48fa-cb59-9b82065ab239"},"outputs":[],"source":["!pip install --upgrade git+https://github.com/huggingface/transformers.git"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3516,"status":"ok","timestamp":1723128933801,"user":{"displayName":"utkarsh patidar","userId":"01573665842487995951"},"user_tz":-330},"id":"RiaQ9VYTJ3qx","outputId":"a132c461-6f98-4693-b1d7-96a92bb8f1a9"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1193,"status":"ok","timestamp":1723128934990,"user":{"displayName":"utkarsh patidar","userId":"01573665842487995951"},"user_tz":-330},"id":"VkchU32xKlmo","outputId":"e5794031-d870-4924-8f43-25e63a27b9c6"},"outputs":[],"source":["# !ls \"/content/drive/MyDrive/multilabel_modified/images\""]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4159,"status":"ok","timestamp":1723128939147,"user":{"displayName":"utkarsh patidar","userId":"01573665842487995951"},"user_tz":-330},"id":"mvv89jPVkMK8"},"outputs":[],"source":["!pip install -q datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":348},"executionInfo":{"elapsed":3407,"status":"ok","timestamp":1723128942552,"user":{"displayName":"utkarsh patidar","userId":"01573665842487995951"},"user_tz":-330},"id":"k7--SbXXkbF5","outputId":"99ced46c-3793-4224-d82c-564aee5dc355"},"outputs":[],"source":["import pandas as pd\n","df=pd.read_csv(\"/Users/utkarshpatidar/Downloads/finetune_SigLip_for_multi image_clasification /multilabel_modified/multilabel_classification(2).csv\")\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":452},"executionInfo":{"elapsed":1537,"status":"ok","timestamp":1723128944086,"user":{"displayName":"utkarsh patidar","userId":"01573665842487995951"},"user_tz":-330},"id":"LD6Ry6GBnCub","outputId":"59da9fa3-8915-4ac2-a007-3c78d310ae9e"},"outputs":[],"source":["# @title boat\n","import matplotlib\n","from matplotlib import pyplot as plt\n","df['boat'].plot(kind='hist', bins=20, title='boat')\n","plt.gca().spines[['top', 'right',]].set_visible(False)"]},{"cell_type":"markdown","metadata":{"id":"WZ42mFt0g9Ec"},"source":["# New section"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1723128944086,"user":{"displayName":"utkarsh patidar","userId":"01573665842487995951"},"user_tz":-330},"id":"nHu-IkvqmxFV","outputId":"27023b21-e5d3-4879-b935-f592be0029de"},"outputs":[],"source":["df.iloc[0][2:].values"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1723128944086,"user":{"displayName":"utkarsh patidar","userId":"01573665842487995951"},"user_tz":-330},"id":"vPxl5DsRngmp","outputId":"72e59333-0ade-4cc8-aa4f-073c3f48d1e2"},"outputs":[],"source":["labels = list(df.columns)[2:]\n","print(labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1723128944087,"user":{"displayName":"utkarsh patidar","userId":"01573665842487995951"},"user_tz":-330},"id":"_fG1rnjvn1TO","outputId":"356c0df7-7c56-4828-c0e0-2a36730f19d0"},"outputs":[],"source":["id2label={id:label for id , label in enumerate(labels)}\n","print(id2label)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24619,"status":"ok","timestamp":1723128968704,"user":{"displayName":"utkarsh patidar","userId":"01573665842487995951"},"user_tz":-330},"id":"tk8FSeBHodIh","outputId":"4138472e-f222-4f34-e26c-59e9671d8892"},"outputs":[],"source":["from transformers import AutoImageProcessor, AutoModelForImageClassification\n","\n","model_id = \"google/siglip-so400m-patch14-384\"\n","\n","processor = AutoImageProcessor.from_pretrained(model_id)\n","model = AutoModelForImageClassification.from_pretrained(model_id, problem_type=\"multi_label_classification\", id2label=id2label)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":24,"status":"ok","timestamp":1723128968704,"user":{"displayName":"utkarsh patidar","userId":"01573665842487995951"},"user_tz":-330},"id":"tbYGjdMXp1bF"},"outputs":[],"source":["from torch.utils.data import Dataset\n","import torch\n","from PIL import Image\n","import os\n","import numpy as np\n","\n","class MultiLabelDataset(Dataset):\n","  def __init__(self, root, df, transform):\n","    self.root = root\n","    self.df = df\n","    self.transform = transform\n","\n","  def __getitem__(self, idx):\n","    item = self.df.iloc[idx]\n","    # get image\n","    image_path = os.path.join(self.root, item[\"Image_Name\"])\n","    if os.path.exists(image_path):\n","       image = Image.open(image_path).convert(\"RGB\")\n","    else:\n","            print(f\"Error: Image not found at {image_path}\")\n","    # prepare image for the model\n","    pixel_values = self.transform(image)\n","\n","    # get labels\n","    labels = item[2:].values.astype(np.float32)\n","\n","    # turn into PyTorch tensor\n","    labels = torch.from_numpy(labels)\n","\n","    return pixel_values, labels\n","\n","  def __len__(self):\n","    return len(self.df)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":23,"status":"ok","timestamp":1723128968704,"user":{"displayName":"utkarsh patidar","userId":"01573665842487995951"},"user_tz":-330},"id":"lusEunoBqQqB"},"outputs":[],"source":["from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n","\n","# get appropriate size, mean and std based on the image processor\n","size = processor.size[\"height\"]\n","mean = processor.image_mean\n","std = processor.image_std\n","\n","transform = Compose([\n","    Resize((size, size)),\n","    ToTensor(),\n","    Normalize(mean=mean, std=std),\n","])\n","\n","train_dataset = MultiLabelDataset(root=\"/Users/utkarshpatidar/Downloads/finetune_SigLip_for_multi image_clasification /multilabel_modified/images\",\n","                                  df=df, transform=transform)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1723128968704,"user":{"displayName":"utkarsh patidar","userId":"01573665842487995951"},"user_tz":-330},"id":"7yQv0uPRDJD5","outputId":"83b8c682-4eb3-431b-dfce-90035a3a4cf1"},"outputs":[],"source":["pixel_values, labels = train_dataset[63]\n","print(pixel_values.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1723128968704,"user":{"displayName":"utkarsh patidar","userId":"01573665842487995951"},"user_tz":-330},"id":"jkxSxnnSJwoQ"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1723128968704,"user":{"displayName":"utkarsh patidar","userId":"01573665842487995951"},"user_tz":-330},"id":"2y1X3kD8Jy0E"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":401},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1723128968704,"user":{"displayName":"utkarsh patidar","userId":"01573665842487995951"},"user_tz":-330},"id":"FqPbuC08DJNg","outputId":"3617468e-0574-4f41-d48e-df1bf0c97533"},"outputs":[],"source":["unnormalized_image = (pixel_values.numpy() * np.array(std)[:, None, None]) + np.array(mean)[:, None, None]\n","unnormalized_image = (unnormalized_image * 255).astype(np.uint8)\n","unnormalized_image = np.moveaxis(unnormalized_image, 0, -1)\n","Image.fromarray(unnormalized_image)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1723128968704,"user":{"displayName":"utkarsh patidar","userId":"01573665842487995951"},"user_tz":-330},"id":"Zooa7i0uECAu"},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","def collate_fn(batch):\n","    data = torch.stack([item[0] for item in batch])\n","    target = torch.stack([item[1] for item in batch])\n","    return data, target\n","\n","train_dataloader = DataLoader(train_dataset, collate_fn=collate_fn, batch_size=2, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":445,"status":"ok","timestamp":1723128969130,"user":{"displayName":"utkarsh patidar","userId":"01573665842487995951"},"user_tz":-330},"id":"9L-yRkU6EBwV","outputId":"9189946b-4b7a-4049-838a-a9ae20089680"},"outputs":[],"source":["batch = next(iter(train_dataloader))\n","print(batch)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":36587,"status":"ok","timestamp":1723129015679,"user":{"displayName":"utkarsh patidar","userId":"01573665842487995951"},"user_tz":-330},"id":"5eZaCI5nXEXl"},"outputs":[],"source":["import torch\n","\n","# Set the device to CPU\n","device = torch.device(\"cpu\")\n","\n","# Ensure the model is on the CPU\n","model.to(device)\n","\n","# Example forward pass\n","outputs = model(pixel_values=batch[0].to(device), labels=batch[1].to(device))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":712,"status":"ok","timestamp":1723129020193,"user":{"displayName":"utkarsh patidar","userId":"01573665842487995951"},"user_tz":-330},"id":"mXFyCrhKEWvA","outputId":"8081bff4-689a-4891-9d35-da7e884c0cd6"},"outputs":[],"source":["outputs.loss"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":437,"status":"ok","timestamp":1723129022114,"user":{"displayName":"utkarsh patidar","userId":"01573665842487995951"},"user_tz":-330},"id":"_h65lFUYEaDh"},"outputs":[],"source":["# handy utility I found at https://github.com/wenwei202/pytorch-examples/blob/ecbb7beb0fac13133c0b09ef980caf002969d315/imagenet/main.py#L296\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s0m-_FFiEZ6q"},"outputs":[],"source":["import torch\n","from torch.optim import AdamW\n","from tqdm.auto import tqdm\n","\n","# move model to GPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","optimizer = AdamW(model.parameters(), lr=5e-5)\n","\n","losses = AverageMeter()\n","\n","model.train()\n","for epoch in range(10):  # loop over the dataset multiple times\n","    for idx, batch in enumerate(tqdm(train_dataloader)):\n","        # get the inputs;\n","        pixel_values, labels = batch\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward pass\n","        outputs = model(\n","            pixel_values=pixel_values.to(device),\n","            labels=labels.to(device),\n","        )\n","\n","        # calculate gradients\n","        loss = outputs.loss\n","        losses.update(loss.item(), pixel_values.size(0))\n","        loss.backward()\n","\n","        # optimization step\n","        optimizer.step()\n","\n","        if idx % 100 == 0:\n","            print('Epoch: [{0}]\\t'\n","                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(\n","                   epoch, loss=losses,))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b-OcSFUKEjL4"},"outputs":[],"source":["# load image to test on\n","image = Image.open(\"/Users/utkarshpatidar/Downloads/finetune_SigLip_for_multi image_clasification /multilabel_modified/images/image7841.jpg\")\n","image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JOa33v5JElPI"},"outputs":[],"source":["model.eval()\n","\n","# prepare image for the model\n","pixel_values = processor(image, return_tensors=\"pt\").pixel_values.to(device)\n","\n","# forward pass\n","with torch.no_grad():\n","  outputs = model(pixel_values)\n","  logits = outputs.logits"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oohHJUvBEl_D"},"outputs":[],"source":["# turn into probabilities by applying sigmoid\n","sigmoid = torch.nn.Sigmoid()\n","probs = sigmoid(logits.squeeze().cpu())\n","\n","# select the probabilities > a certain threshold (e.g. 50%) as predicted\n","predictions = np.zeros(probs.shape)\n","predictions[np.where(probs >= 0.5)] = 1 # turn predicted id's into actual label names\n","predicted_labels = [id2label[idx] for idx, label in enumerate(predictions) if label == 1.0]\n","print(predicted_labels)\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMhSYvkmTz1yy0LiGcEn1gc","mount_file_id":"1_t4gfn_19T9rWnTi9E61cmcY_TTlRd7x","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":0}
